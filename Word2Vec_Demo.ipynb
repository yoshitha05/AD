{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoshitha05/AD/blob/main/Word2Vec_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd1ae7bb",
      "metadata": {
        "id": "cd1ae7bb"
      },
      "source": [
        "Sample sentences :\n",
        "    \n",
        "1) Welcome to Malla Reddy\n",
        "2) Malla Reddy has CSE stream\n",
        "3) CSE stream in Malla Reddy is best\n",
        "\n",
        "Corpus :\n",
        "Welcome, to , Malla, Reddy, hass, CSE, Stream, in, is, best  - 10 D vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84095593",
      "metadata": {
        "id": "84095593"
      },
      "source": [
        "Embeddings in ndimensional space"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is Cosine Similarity & Distance**"
      ],
      "metadata": {
        "id": "8vohrAAuCrf0"
      },
      "id": "8vohrAAuCrf0"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bVn-guSC_VwG"
      },
      "id": "bVn-guSC_VwG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4158167b",
      "metadata": {
        "id": "4158167b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5c33d28c",
      "metadata": {
        "id": "5c33d28c"
      },
      "source": [
        "### Loading a pre trained google news word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fc20628c",
      "metadata": {
        "id": "fc20628c",
        "outputId": "877d6a84-5e0a-4c00-e17e-5d61cd739c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Here we're trying to get the embeddings and words that are being trained by google in Wikipedia\n",
        "model = api.load(\"fasttext-wiki-news-subwords-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e0354f21",
      "metadata": {
        "id": "e0354f21",
        "outputId": "6555fdc7-b591-49f3-f839-a1943e4a4d5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.2063e-01  5.1695e-03 -1.2447e-02 -7.8528e-03 -2.3738e-02 -8.2595e-02\n",
            "  4.5790e-02 -1.5382e-01  6.4550e-02  1.2893e-01  2.7643e-02  1.5958e-02\n",
            "  7.7559e-02  6.0516e-02  1.2737e-01  8.4766e-02  6.3890e-02 -1.7687e-01\n",
            "  4.3017e-02 -1.8031e-02 -3.3041e-02  2.1930e-02 -1.1328e-02  6.6453e-02\n",
            "  1.5826e-01 -2.3008e-02 -4.3616e-03 -2.2379e-02  4.4891e-02  3.0103e-03\n",
            " -1.5565e-02 -7.6785e-02 -9.2186e-02  5.7907e-02 -2.7658e-02  5.4500e-03\n",
            "  1.8975e-02  4.2939e-02  3.4704e-03  4.0449e-02 -4.0245e-03 -1.1594e-01\n",
            " -5.8337e-03  3.2509e-02 -8.6535e-02  7.2000e-02 -2.2299e-02  1.3079e-02\n",
            " -3.9515e-02  6.8996e-02  9.2300e-02 -7.5371e-02  5.9412e-03 -3.4945e-02\n",
            " -3.3417e-02 -9.9982e-02  1.6438e-02  6.3739e-02 -6.2391e-02  7.8285e-04\n",
            " -2.9210e-02 -9.6416e-02  7.2910e-02  4.5905e-02 -8.3387e-02  7.1969e-02\n",
            "  4.0932e-02 -5.6454e-03  1.3709e-01 -1.1793e-01 -7.1011e-02 -7.1963e-02\n",
            "  6.5600e-02 -4.6315e-02 -1.7200e-02  3.4434e-02  4.4218e-02 -9.6354e-03\n",
            " -6.8105e-02  3.0810e-02  1.5424e-02  5.6398e-02  4.4225e-02  8.0547e-02\n",
            " -5.2413e-02 -3.6509e-02  2.6141e-02  2.5574e-02 -3.4346e-02 -4.5879e-02\n",
            " -1.7031e-02  5.1450e-02 -1.2766e-01 -8.6838e-02  1.1084e-02  1.3282e-01\n",
            "  2.0850e-02  7.0881e-02 -5.9277e-03  2.2612e-02  4.8919e-02 -1.2490e-02\n",
            "  1.5460e-01 -6.1251e-03 -8.9369e-02 -2.3707e-01  2.0696e-02 -3.7604e-02\n",
            " -8.3793e-02 -2.5512e-03 -4.0426e-02  1.0575e-01  9.7514e-02  4.4101e-02\n",
            "  4.1732e-02  7.4080e-02  6.3560e-02  3.1801e-02 -1.4961e-02 -4.3675e-03\n",
            " -1.4893e-02  8.6208e-02 -2.0204e-02 -2.0797e-03  7.7648e-02 -1.9620e-03\n",
            "  3.2115e-02 -1.5615e-01 -3.6702e-02  1.2009e-01 -8.0633e-02  4.2894e-02\n",
            " -3.5265e-02  2.2693e-02 -3.3743e-02  1.7573e-02 -7.5089e-02  9.8873e-02\n",
            "  2.7042e-02 -1.7185e-02  1.7489e-02 -1.1096e-01  7.5456e-02 -4.2234e-02\n",
            " -3.7115e-02 -1.2356e-02  1.1243e-02 -4.6907e-02 -5.5681e-02 -6.5216e-02\n",
            "  5.4923e-02  3.7514e-02  5.0259e-02 -7.4453e-02 -2.0440e-02 -8.3293e-02\n",
            " -2.3010e-02 -4.2105e-02 -2.8792e-02 -1.9139e-02  3.6758e-02  7.7620e-02\n",
            " -6.3909e-02 -2.9304e-02  3.1128e-02 -1.2056e-02 -3.0854e-02 -2.3162e-02\n",
            " -4.4762e-02  1.2797e-01 -7.7709e-03 -7.7466e-02 -2.7976e-02  5.1038e-02\n",
            " -5.5217e-02  7.5312e-02  3.4093e-02 -3.4833e-03  9.7360e-03  5.8273e-02\n",
            "  9.3454e-02 -4.3781e-02 -4.5870e-02 -7.3544e-02 -4.1269e-02 -9.1712e-02\n",
            " -1.5840e-01  1.1790e-01  3.4210e-02 -2.4719e-02  6.1251e-02  8.2068e-02\n",
            " -1.1710e-01  2.9949e-02 -7.1442e-02  2.2185e-02 -2.4418e-02 -2.5316e-02\n",
            " -5.3970e-02  1.1615e-01 -1.9979e-01  6.8714e-02 -6.1776e-03 -3.9478e-02\n",
            " -1.8856e-02  7.8819e-02  3.0709e-02 -4.7448e-02 -5.0356e-02 -4.0706e-02\n",
            "  1.4722e-01 -4.6420e-02  1.1976e-05  9.2290e-02 -6.1358e-02  6.0161e-05\n",
            "  1.4491e-02 -2.4847e-02  5.6051e-02  1.9206e-02  3.2446e-02  5.0245e-03\n",
            "  1.9242e-02  1.3482e-01  7.3311e-03 -1.0219e-01  7.6724e-02  9.7512e-02\n",
            " -4.9655e-02 -7.2788e-03 -1.1748e-01 -3.5783e-02 -6.9954e-02 -8.8086e-03\n",
            " -1.5677e-02  6.4489e-02 -7.2463e-02 -5.0428e-03  7.5461e-02 -6.0999e-02\n",
            "  9.2653e-02 -5.3002e-02 -9.8853e-02  4.4468e-02  1.5699e-03  1.0594e-02\n",
            "  5.4306e-02  2.1943e-02 -1.4941e-02 -2.9272e-02  1.0173e-01 -2.7459e-02\n",
            " -1.7016e-02  3.7454e-02  8.5015e-02  8.6834e-02 -7.6342e-02  9.5069e-02\n",
            "  4.6912e-02 -2.2718e-02 -7.9839e-02  6.6125e-02  6.2540e-02  2.5836e-02\n",
            "  2.4580e-02  5.1879e-02 -1.8032e-04  4.8657e-02 -1.1875e-01 -2.4103e-02\n",
            "  1.5130e-03  8.0515e-02 -1.0280e-01 -1.3489e-02  7.1108e-02 -6.0643e-02\n",
            " -2.3006e-02 -9.8232e-03 -8.7159e-02  8.5388e-02  5.3778e-02 -8.4714e-02\n",
            "  5.4218e-02 -4.1406e-02  1.0716e-02  6.9728e-02 -8.9833e-03 -8.0539e-02\n",
            " -3.0566e-02  1.0912e-01 -3.9061e-02 -6.3893e-02 -3.3986e-02 -2.0095e-02\n",
            " -6.0904e-02  1.5957e-02 -1.0371e-02  6.7261e-02 -3.0458e-02 -3.1992e-02]\n"
          ]
        }
      ],
      "source": [
        "print(model[\"king\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "28cf19f4",
      "metadata": {
        "id": "28cf19f4",
        "outputId": "a19c5acc-935b-4be0-f32e-1dad40d2fffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('re-read', 0.8062080144882202),\n",
              " ('skim-read', 0.7783752083778381),\n",
              " ('pre-read', 0.7726657390594482),\n",
              " ('skimread', 0.7500290870666504),\n",
              " ('reread', 0.7465227842330933),\n",
              " ('write', 0.7422341108322144),\n",
              " ('half-read', 0.7330874800682068),\n",
              " ('reade', 0.7301486730575562),\n",
              " ('read--and', 0.7275975346565247),\n",
              " ('reading', 0.7233502268791199)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# we're trying to get similar words for the Word \"king\"\n",
        "# model.most_similar(\"king\")\n",
        "model.most_similar(\"read\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "568aeee7",
      "metadata": {
        "id": "568aeee7",
        "outputId": "bcd51ef7-d6b6-4f06-e65c-77ac5474e873",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7786749005317688),\n",
              " ('queen-mother', 0.7143871784210205),\n",
              " ('king-', 0.6981282234191895),\n",
              " ('queen-consort', 0.6724597811698914),\n",
              " ('monarch', 0.6666999459266663),\n",
              " ('child-king', 0.6663159132003784),\n",
              " ('boy-king', 0.660534679889679),\n",
              " ('princess', 0.653827428817749),\n",
              " ('ex-queen', 0.652145504951477),\n",
              " ('kings', 0.6497675180435181)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# we're trying to get semantic terms here\n",
        "model.most_similar(positive=['king', 'woman'], negative=['man'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "72664be6",
      "metadata": {
        "id": "72664be6",
        "outputId": "426e6707-81ad-44b9-c269-3ce6843f383b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'car'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# The same happens here\n",
        "model.doesnt_match([\"apple\", \"banana\", \"car\", \"mango\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ba42d34c",
      "metadata": {
        "id": "ba42d34c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9c736233",
      "metadata": {
        "id": "9c736233"
      },
      "source": [
        "### Training Own model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b9de3383",
      "metadata": {
        "id": "b9de3383"
      },
      "outputs": [],
      "source": [
        "# Here we tokenize the words\n",
        "sentences = [\n",
        "    [\"machine\", \"learning\", \"is\", \"amazing\"],\n",
        "    [\"deep\", \"learning\", \"is\", \"a\", \"subset\", \"of\", \"machine\", \"learning\"],\n",
        "    [\"artificial\", \"intelligence\", \"is\", \"the\", \"future\"],\n",
        "    [\"word2vec\", \"converts\", \"words\", \"into\", \"vectors\"]\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "c9fa77b1",
      "metadata": {
        "id": "c9fa77b1"
      },
      "outputs": [],
      "source": [
        "# vector size matlab 2D or 3D or 10D or it can be 50 or 100 too\n",
        "from gensim.models import Word2Vec\n",
        "model2 = Word2Vec(sentences, vector_size=50, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a2c9a318",
      "metadata": {
        "id": "a2c9a318",
        "outputId": "72217cc8-8f01-406b-8e1f-acc8a95f25a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.01723938,  0.00733148,  0.01037977,  0.01148388,  0.01493384,\n",
              "       -0.01233535,  0.00221123,  0.01209456, -0.0056801 , -0.01234705,\n",
              "       -0.00082045, -0.0167379 , -0.01120002,  0.01420908,  0.00670508,\n",
              "        0.01445134,  0.01360049,  0.01506148, -0.00757831, -0.00112361,\n",
              "        0.00469675, -0.00903806,  0.01677746, -0.01971633,  0.01352928,\n",
              "        0.00582883, -0.00986566,  0.00879638, -0.00347915,  0.01342277,\n",
              "        0.0199297 , -0.00872489, -0.00119868, -0.01139127,  0.00770164,\n",
              "        0.00557325,  0.01378215,  0.01220219,  0.01907699,  0.01854683,\n",
              "        0.01579614, -0.01397901, -0.01831173, -0.00071151, -0.00619968,\n",
              "        0.01578863,  0.01187715, -0.00309133,  0.00302193,  0.00358008],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model2.wv[\"machine\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0cf1507b",
      "metadata": {
        "id": "0cf1507b",
        "outputId": "4cf2ede6-364a-49f2-dd29-13cf1ba2a7c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('amazing', 0.22978782653808594),\n",
              " ('into', 0.12474432587623596),\n",
              " ('of', 0.08057719469070435),\n",
              " ('words', 0.07399576157331467),\n",
              " ('is', 0.042335789650678635),\n",
              " ('future', 0.018270451575517654),\n",
              " ('a', 0.011395085602998734),\n",
              " ('machine', 0.011071980930864811),\n",
              " ('artificial', 0.0013571369927376509),\n",
              " ('deep', -0.012010578997433186)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Here model2 is the model created by user and it takes similar words from the given input data i.e., by Us.\n",
        "model2.wv.most_similar(\"learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e72cc358",
      "metadata": {
        "id": "e72cc358",
        "outputId": "2bb05aea-570e-496d-b29f-7e1721d25441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('learning-', 0.8094813227653503),\n",
              " ('re-learning', 0.794863760471344),\n",
              " ('teaching', 0.7599883675575256),\n",
              " ('teaching-learning', 0.7479857802391052),\n",
              " ('unlearning', 0.7443557977676392),\n",
              " ('learning-related', 0.732554018497467),\n",
              " ('learning-oriented', 0.730055034160614),\n",
              " ('non-learning', 0.7299908995628357),\n",
              " ('relearning', 0.7285575270652771),\n",
              " ('learing', 0.7273047566413879)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Here model is a library and it takes similar words from google instead of our data given as input\n",
        "model.most_similar(\"learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "39647f94",
      "metadata": {
        "id": "39647f94"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "from numpy.linalg import norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8f7d800c",
      "metadata": {
        "id": "8f7d800c",
        "outputId": "053a61f9-baaa-47f1-bf46-6bebee973a7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.712976"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Distance - This distance helps us understand how similar the given words are, lesser the distance it has, the more similar they're\n",
        "# norm(model[\"man\"] - model[\"woman\"])\n",
        "# norm(model[\"apple\"] - model[\"banana\"])\n",
        "norm(model[\"apple\"] - model[\"apples\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "114f69ce",
      "metadata": {
        "id": "114f69ce",
        "outputId": "0ecf74a3-123b-45fb-8f69-4e0dc90bfd37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5992496782686327"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Cos Similarity\n",
        "cosine(model[\"kingdom\"], model[\"people\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5e1e3821",
      "metadata": {
        "id": "5e1e3821"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}